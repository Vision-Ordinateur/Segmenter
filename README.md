# Description
Ce projet pr√©sente une √©tude progressive de la segmentation s√©mantique par Transformers. Il d√©bute par l‚Äôanalyse et l‚Äôexp√©rimentation de la segmentation multi-classes √† l‚Äôaide du mod√®le Segmenter, avant d‚Äôaborder un cas d‚Äôusage cibl√© portant sur la segmentation de la classe personne en environnement int√©rieur. Cette d√©marche permet d‚Äô√©valuer √† la fois les capacit√©s g√©n√©rales du mod√®le et son adaptation √† une application sp√©cifique.

## Objectifs du projet
- Comprendre les principes de la segmentation s√©mantique
- √âtudier l‚Äôarchitecture du mod√®le **Segmenter**
- Exp√©rimenter la segmentation multi-classes bas√©e sur les Transformers
- Adapter l‚Äôapproche √† un cas d‚Äôusage cibl√© (classe *personne*)
- Comparer une approche sp√©cialis√©e avec un mod√®le universel (SAM3)



## Phase 1 : Segmentation s√©mantique multi-classes
Dans cette premi√®re phase, le projet s‚Äôest concentr√© sur l‚Äô√©tude et l‚Äôexp√©rimentation de la segmentation s√©mantique g√©n√©rale.  
Le mod√®le Segmenter repose sur une architecture enti√®rement Transformer, compos√©e de :

- **Vision Transformer (ViT)** :  
  L‚Äôimage est d√©coup√©e en patches, projet√©e dans un espace d‚Äôembedding et trait√©e par des couches Transformer afin de capturer des relations globales entre toutes les r√©gions de l‚Äôimage.

- **Mask Transformer** :  
  Les repr√©sentations issues du ViT sont d√©cod√©es afin de produire une carte de segmentation o√π chaque pixel est associ√© √† une classe s√©mantique.

Des tests ont √©t√© r√©alis√©s √† partir d‚Äôun checkpoint pr√©-entra√Æn√©, permettant de g√©n√©rer des cartes de segmentation multi-classes coh√©rentes sur des sc√®nes complexes.



## Phase 2 : Cas d‚Äôusage ‚Äì segmentation de la classe personne
La seconde phase du projet vise un cas d‚Äôusage pr√©cis : la **segmentation de la classe personne dans des sc√®nes int√©rieures**, un enjeu important pour la s√©curit√© et la navigation en robotique domestique.

### Jeu de donn√©es
- Dataset issu de **ADE20K Indoor**
- S√©lection des images contenant des personnes
- Simplification des annotations en deux classes :
  - personne
  - arri√®re-plan
- Pr√©traitement des images et des masques (redimensionnement, normalisation)



## Contraintes techniques
Le fine-tuning du mod√®le Segmenter officiel n‚Äôa pas pu √™tre r√©alis√© en raison de :
- d√©pendances lourdes (mmcv-full, MMSegmentation)
- incompatibilit√©s entre PyTorch, CUDA et les ressources GPU disponibles
- difficult√©s √† obtenir un environnement stable et reproductible

Face √† ces contraintes, une **architecture Transformer simplifi√©e**, inspir√©e de Segmenter, a √©t√© impl√©ment√©e afin de sp√©cialiser le mod√®le sur la classe *personne*.



## Am√©liorations propos√©es
Afin d‚Äôam√©liorer la qualit√© des masques de segmentation, plusieurs am√©liorations ont √©t√© √©tudi√©es :
- **Attention locale** pour mieux capturer les d√©tails fins et les contours
- **Approche multi-√©chelle** pour g√©rer les variations de taille des personnes
- Fusion des caract√©ristiques avant le d√©codage



## Comparaison avec SAM3
Une comparaison a √©t√© effectu√©e avec le mod√®le **SAM3** :
- **Segmenter (approche sp√©cialis√©e)** :
  - segmentation supervis√©e
  - r√©sultats plus pr√©cis pour la classe cible
  - mod√®le plus l√©ger et adapt√© √† une int√©gration embarqu√©e

- **SAM3** :
  - segmentation universelle (zero-shot)
  - g√©n√©ration de nombreux masques non pertinents dans un cas d‚Äôusage cibl√©
  - co√ªt computationnel plus √©lev√©

Cette comparaison montre qu‚Äôun mod√®le sp√©cialis√© est plus adapt√© lorsqu‚Äôune segmentation contr√¥l√©e et pr√©cise est requise.



## R√©sultats
- Segmentation multi-classes globalement coh√©rente
- Bonne d√©tection de la classe personne en environnement int√©rieur
- Limites observ√©es :
  - impr√©cisions sur les contours
  - difficult√©s sur les objets fins ou les zones complexes



## Technologies utilis√©es
- Python
- PyTorch
- Vision Transformers (ViT)
- Transformers
- Traitement et analyse d‚Äôimages

---

## üéì Contexte acad√©mique
Projet r√©alis√© dans le cadre d‚Äôun **Master en Intelligence Artificielle**, orient√© **Vision par Ordinateur et Robotique**.
